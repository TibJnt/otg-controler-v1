## 1. Objectif de lâ€™outil

Un **petit outil local** qui :

1. ContrÃ´le un ou plusieurs iPhones via **iMouseXP** (scroll, tap).
2. Prend des **screenshots** de ton app (ton faux TikTok).
3. Envoie le screenshot Ã  **OpenAI Vision** pour savoir ce quâ€™il y a dans la vidÃ©o.
4. Applique des **rÃ¨gles simples** (â€œsi la vidÃ©o contient *dance* â†’ Likeâ€, etc.).
5. ExÃ©cute les actions (Like, Comment, Save) avec des clics aux coordonnÃ©es configurÃ©es.

Tout Ã§a :

* tourne sur **ta machine Windows** oÃ¹ iMouseXP est installÃ© ;
* utilise **des fichiers JSON locaux** pour garder la config (pas de vraie base de donnÃ©es) ;
* est utilisÃ© par **toi uniquement**.

---

## 2. Contraintes & non-objectifs

* âœ… **Local only** : pas de cloud, pas de multi-user.
* âœ… **Pas de base de donnÃ©es** : juste des fichiers `.json` sur disque.
* âœ… **Une seule automation active Ã  la fois** (un bouton Start/Stop).
* âœ… **Interface trÃ¨s simple** (ton Ã©cran actuel : Select devices, Automation settings, Automation actionsâ€¦).
* âŒ Pas de gestion dâ€™utilisateurs, de droits, etc.
* âŒ Pas de scheduler complexe (pas de â€œlancer demain Ã  3h du matinâ€, seulement bouton Start/Stop).
* âŒ Pas de monitoring avancÃ©, seulement un log texte/console basique.

---

## 3. Vue dâ€™ensemble du systÃ¨me

### 3.1. Composants

1. **iMouseXP (existant)**

   * Logiciel Windows qui expose une API locale.
   * Capable de :

     * **lister les devices** connectÃ©s,
     * **cliquer** Ã  des coordonnÃ©es,
     * **swipe** pour scroller,
     * **prendre un screenshot**.

2. **ContrÃ´leur dâ€™automation (process â€œbackendâ€)**

   * Petit programme local qui :

     * appelle lâ€™API dâ€™iMouseXP,
     * envoie les screenshots Ã  lâ€™API OpenAI Vision,
     * applique les rÃ¨gles dâ€™automation,
     * expose une **mini API HTTP locale** pour ton frontend (ou lit ses fichiers JSON directement).

3. **Fichiers de configuration (.json)**

   * `devices.json` : infos sur tes devices + coordonnÃ©es.
   * `automation.json` : paramÃ¨tres de lâ€™automation (intervals, triggers, devices sÃ©lectionnÃ©s).

4. **Frontend (ton UI)**

   * Page unique avec les sections :

     * â€œSelect devicesâ€
     * â€œDevice action coordinatesâ€
     * â€œAutomation settingsâ€
     * â€œAutomation actionsâ€
     * Bouton â€œStart Automation / Stop Automationâ€
   * Lit/Ã©crit `automation.json` (via une petite API locale ou directement) et dÃ©clenche Start/Stop.

---

## 4. DonnÃ©es (en mÃ©moire + fichiers JSON)

*(Câ€™est de la **forme**, pas du code Ã  coller :)*

### 4.1. Fichier `devices.json`

But : savoir quels devices tu as, comment tu les appelles, et oÃ¹ sont les boutons.

Pour chaque device :

* `idImouse` : identifiant renvoyÃ© par iMouseXP.
* `label` : nom lisible (ex. â€œiPhone 13 â€“ gaucheâ€).
* `coords` :

  * `like` : `{ xNorm, yNorm }` (coordonnÃ©es normalisÃ©es entre 0 et 1).
  * `comment`: `{ xNorm, yNorm }`
  * `save` : `{ xNorm, yNorm }`
* (optionnel plus tard) `commentSendButton`, `commentInputField` si tu veux gÃ©rer le bouton â€œEnvoyerâ€ prÃ©cisÃ©ment.

**Principe important** :
On stocke **des coordonnÃ©es normalisÃ©es** (0â€“1).
Au runtime, le contrÃ´leur :

1. prend un screenshot,
2. lit sa rÃ©solution (ex. 1170 Ã— 2532),
3. calcule `x = xNorm * largeur`, `y = yNorm * hauteur`,
4. envoie ces (x, y) Ã  iMouseXP pour cliquer.

Ã‡a Ã©vite de refaire toute la calibration si la rÃ©solution change ou si tu clones un device.

---

### 4.2. Fichier `automation.json`

Une seule automation pour lâ€™instant (simple) :

* `name` : nom lisible, ex. `"Dancing Videos"`.
* `deviceIds` : liste dâ€™`idImouse` des devices sur lesquels tu veux exÃ©cuter le scÃ©nario.
* `postIntervalSeconds` : dÃ©lai entre deux **actions** (like/comment/save) sur un mÃªme device.
* `scrollDelaySeconds` : dÃ©lai **entre scroll et analyse** (le temps que la vidÃ©o se charge).
* `triggers` : liste des triggers (rÃ¨gles).
* `running` : boolÃ©en ou status (`"stopped" | "running"`), mis Ã  jour par Start/Stop.

### 4.3. Structure dâ€™un trigger

Un trigger correspond Ã  :

> *â€œSi la vidÃ©o contient X ou Y â†’ faire Like / Comment / Saveâ€*

Pour chaque trigger :

* `action` : `"LIKE"` | `"COMMENT"` | `"SAVE"` | `"LIKE_AND_COMMENT"` | `"SKIP"`.
* `keywords` : liste de mots ou phrases Ã  chercher dans lâ€™analyse vision.

  * ce qui correspond au champ â€œVideo Containsâ€ de ton UI (on split par virgule).
* `deviceIds` (optionnel) : si tu veux que ce trigger ne sâ€™applique quâ€™Ã  certains devices ; sinon il sâ€™applique Ã  tous ceux de `automation.deviceIds`.
* (optionnel pour COMMENT) :

  * `commentTemplates` : liste de phrases possibles.
  * `commentLanguage` : `"fr"` / `"en"` pour guider OpenAI si tu gÃ©nÃ¨res le texte.

---

## 5. Fonctionnement cÃ´tÃ© utilisateur (flows)

### 5.1. Flow 1 â€“ DÃ©couverte des devices (â€œSelect devicesâ€)

1. Tu cliques sur â€œRefresh devicesâ€.
2. Le contrÃ´leur appelle iMouseXP pour rÃ©cupÃ©rer la liste des devices connectÃ©s.
3. Il met Ã  jour `devices.json` (ajoute ceux qui manquent, Ã©ventuellement garde lâ€™alias `label` si dÃ©jÃ  connu).
4. Le frontend affiche :

   * â€œAll Devices (N)â€ avec N = nombre de devices,
   * une liste avec checkboxes pour sÃ©lectionner lesquels participeront Ã  lâ€™automation.

RÃ©sultat attendu : tu coches 1â€“2â€“3 devices qui seront utilisÃ©s par lâ€™automation.

---

### 5.2. Flow 2 â€“ Calibration des coordonnÃ©es (â€œDevice action coordinatesâ€)

Objectif : dire Ã  lâ€™outil â€œici câ€™est Like, ici câ€™est Comment, ici câ€™est Saveâ€.

Pour chaque device sÃ©lectionnÃ© :

1. Tu cliques sur â€œCalibrerâ€ (par exemple).
2. Le contrÃ´leur :

   * demande un screenshot du device Ã  iMouseXP,
   * le renvoie au frontend,
   * le frontend affiche le screenshot dans un canvas.
3. Sur lâ€™UI, tu cliques avec la souris sur le bouton â€œLikeâ€ de lâ€™app :

   * le frontend rÃ©cupÃ¨re les coordonnÃ©es `(x, y)` dans lâ€™image,
   * il calcule `xNorm = x / largeur`, `yNorm = y / hauteur`,
   * il Ã©crit Ã§a dans `devices.json` â†’ `coords.like`.
4. Tu recommences pour â€œCommentâ€ et â€œSaveâ€.

**MVP** :
MÃªme si tu ne fais pas dâ€™UI â€œcanvasâ€, tu peux aussi :

* afficher le screenshot avec un outil externe,
* noter les coordonnÃ©es Ã  la main dans les inputs â€œX/Yâ€ du frontend,
* le frontend les normalise et les sauvegarde.

---

### 5.3. Flow 3 â€“ Configuration de lâ€™automation (â€œAutomation settingsâ€)

Tu remplis dans ton UI :

* **Automation name** : champ texte â†’ `automation.name`.
* **Set the post interval for interaction** :

  * spinner ou champ numÃ©rique â†’ `automation.postIntervalSeconds`.
* **Set the scroll delay for interaction** :

  * spinner ou champ numÃ©rique â†’ `automation.scrollDelaySeconds`.
* Les devices sÃ©lectionnÃ©s dans â€œSelect devicesâ€ sont sauvegardÃ©s dans `automation.deviceIds`.

Le frontend met Ã  jour `automation.json`.

---

### 5.4. Flow 4 â€“ CrÃ©ation des triggers (â€œAutomation actionsâ€)

Dans la partie â€œAutomation actionsâ€ :

1. **Action** : dropdown (â€œLikeâ€, â€œCommentâ€, â€œSaveâ€â€¦).
2. **Trigger Conditions** :

   * champ â€œVideo Containsâ€ (texte libre, ex. `"dance, dancing, girl"`),
   * on transforme Ã§a en `keywords = ["dance", "dancing", "girl"]`.
3. **Assign to Devices** :

   * multi-select,
   * si tu ne choisis rien â†’ le trigger sâ€™applique Ã  tous les devices de `automation.deviceIds`.

Quand tu cliques sur â€œCreate Triggerâ€ :

* le frontend ajoute une entrÃ©e dans `automation.triggers` et rÃ©Ã©crit `automation.json`.

Pour MVP, un **seul type de condition** :

> â€œVideo Containsâ€ â†’ on check si **au moins un** des keywords apparaÃ®t dans lâ€™analyse Vision.

---

### 5.5. Flow 5 â€“ Lancer & arrÃªter lâ€™automation

* Bouton **â€œStart Automationâ€** :

  1. envoie une commande au contrÃ´leur (par ex. `POST /start`),
  2. le contrÃ´leur met `automation.running = true` et lance la boucle.

* Bouton **â€œStop Automationâ€** :

  1. envoie une commande `POST /stop`,
  2. le contrÃ´leur met `automation.running = false` et stoppe toutes les boucles.

Tu peux aussi prÃ©voir un **bouton â€œEmergency Stopâ€** qui force `running = false` tout de suite mÃªme en cas de bug.

---

## 6. Comportement runtime (boucle dâ€™automation)

### 6.1. Boucle globale

Une fois `Start` cliquÃ© et `automation.running = true` :

* Le contrÃ´leur charge `devices.json` + `automation.json`.
* Il construit la liste `devicesActifs = intersection(automation.deviceIds, devices connus)`.

MVP : **une seule boucle** qui tourne, et Ã  chaque â€œtickâ€ parcourt tous les devices actifs.

SchÃ©ma :

1. Tant que `running = true` :

   * pour chaque device actif :

     1. ExÃ©cuter un â€œcycleâ€ (scroll â†’ analyse â†’ action).
   * recommencer.

Ã‡a Ã©vite dâ€™avoir de la vraie concurrence (threads) et reste simple.

---

### 6.2. Cycle pour un device

Pour un device donnÃ© (un passage dans la boucle) :

1. **Scroll vers la prochaine vidÃ©o**

   * envoyer Ã  iMouseXP un swipe vertical (direction â€œupâ€ ou â€œdownâ€ fixe pour tous les devices).
2. **Attendre** `scrollDelaySeconds` (avec un peu de random, ex. Â±20 %).
3. **Prendre un screenshot**

   * demander Ã  iMouseXP un screenshot pour ce device.
4. **Analyse Vision**

   * envoyer le screenshot Ã  OpenAI Vision,
   * obtenir une rÃ©ponse structurÃ©e avec :

     * une courte description,
     * une liste de mots-clÃ©s / tags.
5. **Ã‰valuation des triggers**

   * construire une string `texteAnalyse` avec description + tags.
   * pour chaque trigger applicable Ã  ce device :

     * vÃ©rifier si **au moins un** `keyword` est prÃ©sent (case-insensitive) dans `texteAnalyse`.
   * si plusieurs triggers matchent :

     * MVP : prendre le **premier** dans la liste.
   * si aucun ne matche :

     * action = aucune (juste scroll).
6. **ExÃ©cuter lâ€™action**

   * `LIKE` :

     * calculer (x, y) Ã  partir des `coords.like` du device,
     * envoyer un clic Ã  ces coordonnÃ©es.
   * `COMMENT` (MVP simple) :

     * clic sur `coords.comment` pour ouvrir la zone de commentaires,
     * insÃ©rer un texte simple (ex. choisi au hasard dans `commentTemplates` ou une phrase fixe),
     * clic sur une coordonnÃ©e â€œEnvoyerâ€ (optionnel dans la v1 si tu ne veux pas te prendre la tÃªte).
   * `SAVE` :

     * idem que Like avec `coords.save`.
7. **Attendre** `postIntervalSeconds` (Â± un peu de random), puis passer au device suivant.

RÃ©-exÃ©cutÃ© en boucle tant que lâ€™automation est en cours.

---

## 7. â€œHumanisationâ€ minimale

Sans overengineering, juste 2â€“3 trucs :

* Ajouter une **variation alÃ©atoire** sur les dÃ©lais :

  * `scrollDelaySeconds` Ã— (entre 0.8 et 1.2),
  * `postIntervalSeconds` Ã— (entre 0.7 et 1.3).
* Ne pas toujours liker :

  * mÃªme si un trigger matche, tu peux dÃ©finir dans la spec :

    * `probability` pour chaque action (ex. 0.8 de like, 0.2 de ne rien faire).
* Parfois juste scroller sans action :

  * ex. 1 cycle sur 3 tu ignore volontairement les triggers (mÃªme si Ã§a matche).

Tout Ã§a reste dans la logique, pas besoin de systÃ¨me compliquÃ©.

---

## 8. Gestion des erreurs (simple)

SpÃ©cifier un comportement ultra basique :

* **Pas de device** :

  * si `devicesActifs` est vide au moment de Start :

    * refuser de dÃ©marrer avec un message â€œNo devices availableâ€.
* **Coords manquantes** :

  * au lancement, vÃ©rifier que chaque device a des `coords.like` (et autres si utilisÃ©s),
  * sinon, log â€œMissing coordinates for device X, skippingâ€.
* **Ã‰chec screenshot** :

  * log lâ€™erreur,
  * sauter ce cycle pour ce device.
* **Erreur API Vision** :

  * log lâ€™erreur,
  * ne faire aucune action sur ce cycle (juste continuer Ã  scroller sur les suivants).
* **Stop demandÃ©** :

  * dÃ¨s que `running` passe Ã  false, le contrÃ´leur termine la boucle en cours et ne rÃ©enclenche plus de cycle.

---

## 9. Logging minimal

Comme câ€™est un outil perso :

* Affichage console du type :

  * `[10:32:01] Device iPhone 13: scroll â†’ description="girl dancing", action=LIKE`
  * `[10:32:10] Device iPhone 13: no trigger matched`
* Optionnel : un fichier `automation.log` pour rejouer ce qui sâ€™est passÃ©.

---

## 10. Plan dâ€™implÃ©mentation simple (sans code)

1. **ImplÃ©menter un petit client iMouseXP**

   * Fonctions : lister devices, swipe, click, screenshot.
2. **GÃ©rer les fichiers `devices.json` et `automation.json`**

   * Lecture/Ã©criture simple, sans ORM, sans DB.
3. **Brancher ton UI**

   * Boutons â€œRefresh devicesâ€, â€œSave coordinatesâ€, â€œCreate triggerâ€, â€œStart/Stopâ€.
4. **Faire tourner un premier scÃ©nario**

   * 1 device, 1 trigger (â€œVideo Contains: danceâ€), action = LIKE.
5. **Ajouter petit Ã  petit**

   * Commentaires,
   * Plusieurs devices,
   * Humanisation.

---

Parfait, on garde tout ce que tu as dÃ©jÃ , et on rajoute Ã  la fin une section **â€œDocumentationâ€** que tu peux coller telle quelle dans ton doc de specs.

---

## 11. Documentation

### 11.1. Vue dâ€™ensemble

Ton outil sâ€™appuie sur deux blocs de doc principaux :

1. **Some3C / iMouseXP** â€“ pour tout ce qui est :

   * dÃ©couverte des devices,
   * clics / swipes,
   * screenshots.
2. **OpenAI API** â€“ pour :

   * lâ€™analyse Vision des screenshots,
   * Ã©ventuellement la gÃ©nÃ©ration de texte (commentaires).

Lâ€™idÃ©e : Ã  chaque Ã©tape de la spec (Lister devices, Scroll, Screenshot, Analyse, Action), tu sais **exactement** dans quelle page de doc aller.

---

### 11.2. Documentation iMouseXP / Some3C

#### 11.2.1. Installation & interface iMouseXP

* **iMouse XP New version**
  Page : â€œiMouse XP New versionâ€ dans â€œiPhone Farm Setupâ€. ([doc.some3c.com][1])
  Utile pour :

  * prÃ©requis systÃ¨me,
  * installation / dÃ©sinstallation,
  * diffÃ©rence entre *Kernel* et *Console*,
  * dÃ©marrage de la console.

ğŸ‘‰ RÃ©fÃ©rence lorsque tu prÃ©pares la machine Windows qui hÃ©berge iMouseXP et ton contrÃ´leur.

---

#### 11.2.2. API gÃ©nÃ©rale (HTTP / WebSocket)

* **XP API Documentation**
  Page : â€œXP API Documentationâ€. ([doc.some3c.com][2])
  Utile pour :

  * comprendre les ports (HTTP & WebSocket sur `9911`),
  * format gÃ©nÃ©ral des requÃªtes (`fun`, `data`),
  * codes de retour (`status`, `data.code`â€¦).

Liens avec ta spec :

* Quand tu parles de **â€œpetit client iMouseXPâ€** dans ton contrÃ´leur (Section 10), tu te bases sur :

  * lâ€™URL : `http://<ip-imouse>:9911/api`
  * le format JSON de base dÃ©crit ici.

---

#### 11.2.3. Lister les devices (Select devices)

* **Equipment related â†’ 1. Get device list**
  Page : â€œEquipment relatedâ€, section `1. Get device list`. ([doc.some3c.com][3])
  Endpoint : `/device/get`

Ce que tu en tires pour ta spec :

* Correspond Ã  ton step **â€œRefresh devicesâ€** dans la section *Select devices*.
* Tu rÃ©cupÃ¨res :

  * `deviceid`, `device_name`, `width`, `height`, `gname`, `state`, etc.
* Tu utilises ces champs pour :

  * remplir `devices.json` (idImouse, label, width/heightâ€¦),
  * alimenter la liste â€œAll Devices (N)â€ dans lâ€™UI.

---

#### 11.2.4. ContrÃ´le souris & clavier (actions Like / Comment / Save / Scroll)

* **Keyboard and Mouse** ([doc.some3c.com][4])
  Principales sections utilisÃ©es :

1. **Mouse clicks**

   * `fun: "/mouse/click"`
   * paramÃ¨tres : `id`, `x`, `y`, `button`, etc.
     â†’ utilisÃ© pour :

     * clic **Like** (coordonnÃ©es `coords.like`),
     * clic **Comment** (coordonnÃ©es `coords.comment`),
     * clic **Save** (coordonnÃ©es `coords.save`),
     * clic sur le bouton â€œEnvoyerâ€ du commentaire.

2. **Mouse slide**

   * `fun: "/mouse/swipe"`
   * paramÃ¨tres : `id`, `direction`, `len`, `stepping`, `step_sleep`, etc.
     â†’ utilisÃ© pour :

     * action **Scroll** dans ta boucle dâ€™automation (passer Ã  la vidÃ©o suivante).

3. **Keyboard Input**

   * section â€œKeyboard Inputâ€ (mÃªme page)
     â†’ utilisÃ© pour :

     * **taper le commentaire** dans le champ de texte aprÃ¨s avoir cliquÃ© sur le bouton â€œcommentâ€.

Lien avec ta spec :

* Tout ce que tu dÃ©cris dans **â€œ5. ExÃ©cuter lâ€™actionâ€** (clic Like/Comment/Save, scroll, entrÃ©e de texte) repose exactement sur ces endpoints.

---

#### 11.2.5. Screenshot & OCR (Picture Text Recognition)

* **Picture Text Recognition** ([doc.some3c.com][5])
  Section utilisÃ©e :

1. **Take a screenshot**

   * `fun: "/pic/screenshot"`
   * paramÃ¨tres : `id`, `binary`, `jpg`, `rect`, `save_path`.
     â†’ utilisÃ© pour :

     * **prendre le screenshot** plein Ã©cran de la vidÃ©o,
     * soit rÃ©cupÃ©rer un fichier local (via `save_path`),
     * soit rÃ©cupÃ©rer des **donnÃ©es binaires** si `binary: true`.

2. (Facultatif) **OCR text recognition / Find text**

   * Si un jour tu veux :

     * rÃ©cupÃ©rer du texte directement depuis lâ€™Ã©cran **sans** passer par OpenAI Vision (par ex. lire un titre, un bouton),
     * faire du â€œFind textâ€ sur la UI.

Lien avec ta spec :

* Câ€™est cette section qui supporte ton step **â€œScreenshot â†’ Analyse Visionâ€** dans la boucle.
* Tu lis ici les dÃ©tails nÃ©cessaires pour implÃ©menter ton wrapper `takeScreenshot(deviceId, binary=true)`.

---

### 11.3. Documentation OpenAI (Vision & Texte)

Pour la partie **â€œAnalyse Visionâ€** de tes specs, et Ã©ventuellement la gÃ©nÃ©ration de commentaires, tu tâ€™appuies sur les docs suivantes :

#### 11.3.1. Guide Images & Vision

* **Images and vision â€“ OpenAI API** ([OpenAI Platform][6])
  Explique :

  * comment envoyer des images (fichiers ou base64) au modÃ¨le,
  * comment demander une rÃ©ponse structurÃ©e (JSON) dÃ©crivant lâ€™image,
  * exemples de prompts et de formats de rÃ©ponse.

Lien avec ta spec :

* Couvre ton step **â€œAnalyse Visionâ€** dans la boucle :

  * Tu y trouves comment appeler le modÃ¨le avec le screenshot renvoyÃ© par iMouseXP,
  * Comment construire la rÃ©ponse type (`caption`, `topics`, etc.) Ã  partir des exemples.

---

#### 11.3.2. Quickstart (mise en place gÃ©nÃ©rale)

* **Developer quickstart â€“ OpenAI API** ([OpenAI Platform][7])
  Utile pour :

  * setup global (API key, client Node/Python),
  * exemples rapides dâ€™appels incluant des images.

Lien avec ta spec :

* Source principale pour la mise en place du **contrÃ´leur dâ€™automation** (partie â€œBackend localâ€) :

  * comment instancier le client,
  * comment faire un simple appel Vision pour un test manuel.

---

#### 11.3.3. API Reference â€“ Chat / Vision

* **Chat API Reference** ([OpenAI Platform][8])
  Utile pour :

  * syntaxe exacte des payloads pour `chat.completions`,
  * comment inclure une image dans les `messages` (role `user`, `content` avec type `input_image`),
  * paramÃ¨tres comme `response_format: { "type": "json_object" }` si tu veux du JSON strict.

Lien avec ta spec :

* Correspond Ã  ton idÃ©e de rÃ©ponse **structurÃ©e** type :

  ```json
  {
    "caption": "...",
    "topics": ["dance", "girl"],
    "should_comment": true,
    "comment_style": "compliment"
  }
  ```

* Tu tâ€™inspires de ces docs pour :

  * construire ton prompt,
  * demander un JSON,
  * parser le rÃ©sultat dans le contrÃ´leur.

---

### 11.4. Comment tout relier rapidement

Voici le mapping â€œspec â†’ docâ€ pour coder sans te perdre :

1. **DÃ©couverte des devices (Select devices / Refresh)**

   * Spec : Section â€œFlow 1 â€“ DÃ©couverte des devicesâ€
   * Docs :

     * XP API Documentation (ports, format global) ([doc.some3c.com][2])
     * Equipment related â†’ `1. Get device list` (/device/get) ([doc.some3c.com][3])

2. **Stocker les infos devices (devices.json)**

   * Spec : Section â€œ4.2 Fichier devices.jsonâ€
   * Docs :

     * RÃ©ponse `/device/get` (width, height, deviceid, gnameâ€¦).

3. **Clics Like / Comment / Save**

   * Spec : â€œ6.2 Cycle pour un device â†’ ExÃ©cuter lâ€™actionâ€
   * Docs :

     * Keyboard and Mouse â†’ `Mouse clicks` (/mouse/click). ([doc.some3c.com][4])

4. **Scroll vertical**

   * Spec : mÃªme section que ci-dessus (scroll)
   * Docs :

     * Keyboard and Mouse â†’ `Mouse slide` (/mouse/swipe). ([doc.some3c.com][4])

5. **Ã‰crire des commentaires**

   * Spec : action `COMMENT`
   * Docs :

     * Keyboard and Mouse â†’ `Keyboard Input`. ([doc.some3c.com][4])

6. **Screenshots**

   * Spec : â€œ6.2 Cycle pour un device â†’ Screenshotâ€
   * Docs :

     * Picture Text Recognition â†’ `Take a screenshot` (/pic/screenshot). ([doc.some3c.com][5])

7. **Analyse Vision**

   * Spec : â€œ6.2 Cycle pour un device â†’ Analyse Vision + Ã‰valuation des triggersâ€
   * Docs :

     * Images & vision guide (comment envoyer lâ€™image, demander un JSON) ([OpenAI Platform][6])
     * Chat API Reference (forme exacte de la requÃªte image+texte). ([OpenAI Platform][8])

8. **Boucle dâ€™automation / logique mÃ©tier**

   * Spec : â€œ6.1 Boucle globaleâ€ et â€œ6.2 Cycle pour un deviceâ€
   * Docs :

     * Quickstart OpenAI pour la mise en place gÃ©nÃ©rale du client ([OpenAI Platform][7])
     * XP API Documentation (gestion des retours `status`, `code`) ([doc.some3c.com][2])

---

[1]: https://doc.some3c.com/iphone-farm-setup/imouse-xp-new-version "iMouse XP New version | Some3C User Manual"
[2]: https://doc.some3c.com/xp-api-documentation "XP API Documentation | Some3C User Manual"
[3]: https://doc.some3c.com/xp-api-documentation/equipment-related "Equipment related | Some3C User Manual"
[4]: https://doc.some3c.com/xp-api-documentation/keyboard-and-mouse "Keyboard and Mouse | Some3C User Manual"
[5]: https://doc.some3c.com/xp-api-documentation/picture-text-recognition "Picture Text Recognition | Some3C User Manual"
[6]: https://platform.openai.com/docs/guides/images-vision?utm_source=chatgpt.com "Images and vision - OpenAI API"
[7]: https://platform.openai.com/docs/quickstart?utm_source=chatgpt.com "Developer quickstart - OpenAI API"
[8]: https://platform.openai.com/docs/api-reference/chat?utm_source=chatgpt.com "API Reference"
